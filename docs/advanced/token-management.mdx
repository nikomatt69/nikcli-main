---
title: 'Token Management'
description: 'Optimize token usage and manage costs in NikCLI'
icon: 'coins'
---

# Token Management

Token management is crucial for optimizing performance and controlling costs when using AI models in NikCLI.

## Token Limits

NikCLI manages tokens automatically with these default limits:

| Limit | Value | Description |
|-------|-------|-------------|
| `MAX_CONTEXT_TOKENS` | 80,000 | Maximum context window |
| `EMERGENCY_TRUNCATE_AT` | 50,000 | Emergency truncation point |
| `MAX_SYSTEM_MESSAGE_TOKENS` | 800 | System message limit |
| `MAX_TOOL_MESSAGE_TOKENS` | 600 | Tool message limit |
| `MAX_RECENT_NON_SYSTEM` | 4 | Recent non-system messages |
| `RAG_CHUNK_TOKENS` | 1,000 | RAG chunk size |
| `RAG_CHUNK_OVERLAP_TOKENS` | 30 | Chunk overlap |

## Model Pricing

### Cost Comparison (per 1M tokens)

| Model | Input | Output | Context Window |
|-------|-------|--------|----------------|
| Claude Sonnet 4 | $3.00 | $15.00 | 200K |
| Claude 3.5 Sonnet | $3.00 | $15.00 | 200K |
| Claude 3 Opus | $15.00 | $75.00 | 200K |
| Claude 3 Haiku | $0.25 | $1.25 | 200K |
| Claude 3.5 Haiku | $0.80 | $4.00 | 200K |
| GPT-5 | $1.25 | $10.00 | 200K |
| GPT-4o | $3.00 | $10.00 | 128K |
| GPT-4o Mini | $0.15 | $0.60 | 128K |
| Gemini 2.5 Pro | $2.50 | $15.00 | 2M |
| Gemini 2.5 Flash | $0.30 | $2.50 | 1M |
| DeepSeek R1 | $0.55 | $2.19 | Varies |
| Grok-3 | $3.00 | $15.00 | Varies |

## Context Window Limits

| Model Family | Context Limit |
|--------------|---------------|
| Claude models | 200,000 |
| GPT-5 | 200,000 |
| GPT-4.1 | 1,000,000 |
| GPT-4o / GPT-4 | 128,000 |
| GPT-3.5-turbo | 16,384 |
| Gemini 2.5 Pro | 2,097,152 |
| Gemini 2.5 Flash | 1,000,000 |
| Gemini 1.5 Pro | 2,097,152 |
| Default | 120,000 |

## Monitoring Usage

```bash
# View token usage
/tokens

# Show usage statistics
/stats

# Check cache performance
/cache stats
```

## Cost Optimization Strategies

### 1. Model Selection

Choose the right model for each task:

```bash
# Simple tasks → cheaper models
/model claude-3-haiku
"Fix this typo in the comment"

# Complex reasoning → capable models
/model claude-3-5-sonnet
"Design microservices architecture"
```

### 2. Enable Caching

```bash
# Enable Redis cache
/redis-enable

# View cache stats
/cache stats

# Clear cache if needed
/cache clear
```

### 3. Context Optimization

Keep context focused:

```bash
# Good: Focused context
/context src/components/

# Avoid: Overly broad context
/context . --recursive
```

### 4. Session Memory Management

```bash
# Compact session memory
/compact

# Aggressive compaction
/super-compact
```

## Feature Flags for Token Optimization

### Semantic Cache

```bash
export NIKCLI_SEMANTIC_CACHE=true
```

Configuration:
- `minSimilarity`: 0.85
- `ttl`: 3600 seconds
- `maxCacheSize`: 100,000 entries
- `cacheBackend`: redis or memory

### Agent Memory

```bash
export NIKCLI_AGENT_MEMORY=true
```

Configuration:
- `maxMemorySize`: 10,000 entries
- `retrievalTopK`: 5
- `maxContextLength`: 8,000 tokens
- `autoLearning`: true

## Display Limits

| Type | Limit | Description |
|------|-------|-------------|
| Conversation Summary | 150 chars | Conversation preview |
| Task Description | 80 chars | Task preview |
| File Preview | 200 chars | File content preview |
| Error Context | 180 chars | Error message preview |

## RAG Configuration

| Setting | Value | Description |
|---------|-------|-------------|
| Chunk Tokens | 1,000 | Size of each chunk |
| Chunk Overlap | 30 tokens | Overlap between chunks |
| Code Min Lines | 60 | Minimum code lines per chunk |
| Code Max Lines | 120 | Maximum code lines per chunk |
| Markdown Min Section | 150 chars | Minimum section size |

## Cache Settings

| Setting | Value | Description |
|---------|-------|-------------|
| System Context | 800 tokens | Cached system context |
| Completion Context | 500 tokens | Cached completion context |

## Best Practices

<CardGroup cols={2}>
  <Card title="Use Model Routing" icon="shuffle">
    Enable adaptive routing to automatically select cost-effective models
    ```bash
    /router on
    /router mode balanced
    ```
  </Card>
  <Card title="Leverage Caching" icon="database">
    Enable caching to avoid redundant API calls
    ```bash
    /cache stats
    /redis-enable
    ```
  </Card>
  <Card title="Batch Operations" icon="layer-group">
    Combine related requests to reduce overhead
    ```bash
    /agent react "create button, input, select components"
    ```
  </Card>
  <Card title="Monitor Usage" icon="chart-line">
    Regularly check token usage and costs
    ```bash
    /stats
    /tokens
    ```
  </Card>
</CardGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Configuration" icon="gear" href="/quickstart/configuration">
    Advanced configuration options
  </Card>
  <Card title="CLI Reference" icon="terminal" href="/cli-reference/commands-overview">
    Complete command reference
  </Card>
</CardGroup>
