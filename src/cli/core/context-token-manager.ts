import { EventEmitter } from 'node:events'
import { type CoreMessage } from 'ai'
import chalk from 'chalk'
import { universalTokenizer, type TokenUsage, type ModelLimits } from './universal-tokenizer-service'
import { adaptiveModelRouter, type ModelRouteDecision } from '../ai/adaptive-model-router'
import { logger } from '../utils/logger'

export interface SessionContext {
  sessionId: string
  provider: string
  model: string
  startTime: Date
  totalInputTokens: number
  totalOutputTokens: number
  totalCost: number
  messageCount: number
  lastActivity: Date
  modelLimits: ModelLimits
}

export interface MessageTokenInfo {
  messageId: string
  role: 'system' | 'user' | 'assistant' | 'tool'
  tokens: number
  cost: number
  timestamp: Date
  cumulativeTokens: number
}

export interface ContextOptimization {
  shouldTrim: boolean
  currentUsage: number
  maxTokens: number
  usagePercentage: number
  recommendation: 'continue' | 'trim_context' | 'switch_model' | 'summarize'
  reason: string
}

/**
 * Real-time Context and Token Manager
 * Tracks token usage throughout chat sessions and provides optimization recommendations
 */
export class ContextTokenManager extends EventEmitter {
  private currentSession: SessionContext | null = null
  private messageHistory: Map<string, MessageTokenInfo> = new Map()
  private conversationMessages: CoreMessage[] = []

  // Configuration
  private readonly WARNING_THRESHOLD = 0.8  // 80%
  private readonly CRITICAL_THRESHOLD = 0.9 // 90%
  private readonly MAX_MESSAGES_HISTORY = 100

  constructor() {
    super()
    this.setupEventListeners()
  }

  private setupEventListeners(): void {
    // Listen to tokenizer events
    universalTokenizer.on('token_count', (data) => {
      this.emit('token_counted', data)
    })

    universalTokenizer.on('messages_token_count', (data) => {
      this.emit('messages_counted', data)
    })
  }

  /**
   * Extract text content from complex content types
   */
  private extractTextContent(content: any): string {
    if (typeof content === 'string') {
      return content
    }

    if (Array.isArray(content)) {
      return content
        .map(part => {
          if (typeof part === 'string') return part
          if (part?.text) return part.text
          if (part?.type === 'text' && part?.text) return part.text
          return ''
        })
        .join('')
    }

    if (content?.text) {
      return content.text
    }

    return JSON.stringify(content)
  }

  /**
   * Start a new chat session with context tracking
   */
  async startSession(
    provider: string,
    model: string,
    sessionId?: string
  ): Promise<SessionContext> {
    // End current session if exists
    if (this.currentSession) {
      await this.endSession()
    }

    const limits = universalTokenizer.getModelLimits(model, provider)

    this.currentSession = {
      sessionId: sessionId || this.generateSessionId(),
      provider,
      model,
      startTime: new Date(),
      totalInputTokens: 0,
      totalOutputTokens: 0,
      totalCost: 0,
      messageCount: 0,
      lastActivity: new Date(),
      modelLimits: limits
    }

    // Clear history for new session
    this.messageHistory.clear()
    this.conversationMessages = []

    logger.info('Started new token tracking session', {
      sessionId: this.currentSession.sessionId,
      provider,
      model,
      contextLimit: limits.context
    })

    this.emit('session_started', this.currentSession)
    return this.currentSession
  }

  /**
   * Track a new message and update session context
   */
  async trackMessage(
    message: CoreMessage,
    messageId?: string,
    isOutput: boolean = false
  ): Promise<MessageTokenInfo> {
    if (!this.currentSession) {
      throw new Error('No active session. Call startSession() first.')
    }

    const id = messageId || this.generateMessageId()
    const tokens = await universalTokenizer.countTokens(
      this.extractTextContent(message.content),
      this.currentSession.model,
      this.currentSession.provider
    )

    // Calculate cost
    const cost = isOutput
      ? universalTokenizer.calculateCost(0, tokens, this.currentSession.model).outputCost
      : universalTokenizer.calculateCost(tokens, 0, this.currentSession.model).inputCost

    // Update session totals
    if (isOutput) {
      this.currentSession.totalOutputTokens += tokens
    } else {
      this.currentSession.totalInputTokens += tokens
    }

    this.currentSession.totalCost += cost
    this.currentSession.messageCount++
    this.currentSession.lastActivity = new Date()

    // Create message info
    const messageInfo: MessageTokenInfo = {
      messageId: id,
      role: message.role,
      tokens,
      cost,
      timestamp: new Date(),
      cumulativeTokens: this.currentSession.totalInputTokens + this.currentSession.totalOutputTokens
    }

    // Store in history
    this.messageHistory.set(id, messageInfo)
    this.conversationMessages.push(message)

    // Keep history manageable
    this.trimMessageHistory()

    // Check if we need optimization
    const optimization = this.analyzeContextOptimization()

    this.emit('message_tracked', {
      messageInfo,
      session: this.currentSession,
      optimization
    })

    // Emit warnings if needed
    if (optimization.usagePercentage >= (this.CRITICAL_THRESHOLD * 100)) {
      this.emit('critical_threshold_reached', {
        session: this.currentSession,
        optimization
      })
    } else if (optimization.usagePercentage >= (this.WARNING_THRESHOLD * 100)) {
      this.emit('warning_threshold_reached', {
        session: this.currentSession,
        optimization
      })
    }

    return messageInfo
  }

  /**
   * Track multiple messages (conversation context)
   */
  async trackConversation(messages: CoreMessage[]): Promise<TokenUsage> {
    if (!this.currentSession) {
      throw new Error('No active session. Call startSession() first.')
    }

    const usage = await universalTokenizer.getTokenUsage(
      messages,
      this.currentSession.model,
      this.currentSession.provider,
      0 // No output tokens for context analysis
    )

    // Update session
    this.currentSession.totalInputTokens = usage.promptTokens
    this.currentSession.totalCost = usage.estimatedCost
    this.currentSession.lastActivity = new Date()

    // Update conversation messages
    this.conversationMessages = [...messages]

    this.emit('conversation_tracked', {
      usage,
      session: this.currentSession,
      optimization: this.analyzeContextOptimization()
    })

    return usage
  }

  /**
   * Analyze current context and provide optimization recommendations
   */
  analyzeContextOptimization(): ContextOptimization {
    if (!this.currentSession) {
      return {
        shouldTrim: false,
        currentUsage: 0,
        maxTokens: 0,
        usagePercentage: 0,
        recommendation: 'continue',
        reason: 'No active session'
      }
    }

    const totalTokens = this.currentSession.totalInputTokens + this.currentSession.totalOutputTokens
    const maxTokens = this.currentSession.modelLimits.context
    const usagePercentage = (totalTokens / maxTokens) * 100

    let recommendation: ContextOptimization['recommendation'] = 'continue'
    let reason = 'Token usage is within acceptable limits'
    let shouldTrim = false

    if (usagePercentage >= (this.CRITICAL_THRESHOLD * 100)) {
      recommendation = 'summarize'
      reason = `Critical usage at ${usagePercentage.toFixed(1)}%. Consider summarizing conversation history.`
      shouldTrim = true
    } else if (usagePercentage >= (this.WARNING_THRESHOLD * 100)) {
      recommendation = 'trim_context'
      reason = `High usage at ${usagePercentage.toFixed(1)}%. Consider trimming older messages.`
      shouldTrim = true
    } else if (usagePercentage >= 50) {
      reason = `Moderate usage at ${usagePercentage.toFixed(1)}%. Monitor for continued growth.`
    }

    return {
      shouldTrim,
      currentUsage: totalTokens,
      maxTokens,
      usagePercentage,
      recommendation,
      reason
    }
  }

  /**
   * Get optimized message context (smart trimming)
   */
  async getOptimizedContext(maxTokens?: number): Promise<{
    messages: CoreMessage[]
    removedCount: number
    tokensSaved: number
    strategy: 'none' | 'trim_oldest' | 'trim_middle' | 'summarize'
  }> {
    if (!this.currentSession || this.conversationMessages.length === 0) {
      return {
        messages: [],
        removedCount: 0,
        tokensSaved: 0,
        strategy: 'none'
      }
    }

    const targetTokens = maxTokens || Math.floor(this.currentSession.modelLimits.context * 0.7)
    const currentTokens = await universalTokenizer.countMessagesTokens(
      this.conversationMessages,
      this.currentSession.model,
      this.currentSession.provider
    )

    if (currentTokens <= targetTokens) {
      return {
        messages: this.conversationMessages,
        removedCount: 0,
        tokensSaved: 0,
        strategy: 'none'
      }
    }

    // Strategy 1: Trim oldest messages (keep system + recent)
    const systemMessages = this.conversationMessages.filter(m => m.role === 'system')
    const nonSystemMessages = this.conversationMessages.filter(m => m.role !== 'system')

    let optimizedMessages: CoreMessage[] = [...systemMessages]
    let tokensUsed = 0

    // Add system message tokens
    for (const msg of systemMessages) {
      tokensUsed += await universalTokenizer.countTokens(this.extractTextContent(msg.content), this.currentSession.model, this.currentSession.provider)
    }

    // Add recent messages from the end
    for (let i = nonSystemMessages.length - 1; i >= 0; i--) {
      const msgTokens = await universalTokenizer.countTokens(
        this.extractTextContent(nonSystemMessages[i].content),
        this.currentSession.model,
        this.currentSession.provider
      )

      if (tokensUsed + msgTokens <= targetTokens) {
        optimizedMessages.unshift(nonSystemMessages[i])
        tokensUsed += msgTokens
      } else {
        break
      }
    }

    // Preserve conversation order
    optimizedMessages.sort((a, b) => {
      const aIndex = this.conversationMessages.indexOf(a)
      const bIndex = this.conversationMessages.indexOf(b)
      return aIndex - bIndex
    })

    const removedCount = this.conversationMessages.length - optimizedMessages.length
    const tokensSaved = currentTokens - tokensUsed

    return {
      messages: optimizedMessages,
      removedCount,
      tokensSaved,
      strategy: 'trim_oldest'
    }
  }

  /**
   * Get session statistics
   */
  getSessionStats(): {
    session: SessionContext | null
    averageTokensPerMessage: number
    tokensPerMinute: number
    costPerMessage: number
    remainingContext: number
    remainingPercentage: number
  } | null {
    if (!this.currentSession) return null

    const totalTokens = this.currentSession.totalInputTokens + this.currentSession.totalOutputTokens
    const remainingTokens = this.currentSession.modelLimits.context - totalTokens
    const sessionDurationMinutes = (Date.now() - this.currentSession.startTime.getTime()) / 60000

    return {
      session: this.currentSession,
      averageTokensPerMessage: this.currentSession.messageCount > 0
        ? totalTokens / this.currentSession.messageCount
        : 0,
      tokensPerMinute: sessionDurationMinutes > 0
        ? totalTokens / sessionDurationMinutes
        : 0,
      costPerMessage: this.currentSession.messageCount > 0
        ? this.currentSession.totalCost / this.currentSession.messageCount
        : 0,
      remainingContext: remainingTokens,
      remainingPercentage: (remainingTokens / this.currentSession.modelLimits.context) * 100
    }
  }

  /**
   * Get current session context
   */
  getCurrentSession(): SessionContext | null {
    return this.currentSession
  }

  /**
   * Get message history
   */
  getMessageHistory(): MessageTokenInfo[] {
    return Array.from(this.messageHistory.values())
      .sort((a, b) => a.timestamp.getTime() - b.timestamp.getTime())
  }

  /**
   * End current session
   */
  async endSession(): Promise<SessionContext | null> {
    if (!this.currentSession) return null

    const endedSession = { ...this.currentSession }

    logger.info('Ended token tracking session', {
      sessionId: endedSession.sessionId,
      duration: Date.now() - endedSession.startTime.getTime(),
      totalTokens: endedSession.totalInputTokens + endedSession.totalOutputTokens,
      totalCost: endedSession.totalCost,
      messageCount: endedSession.messageCount
    })

    this.emit('session_ended', endedSession)

    // Clean up
    this.currentSession = null
    this.messageHistory.clear()
    this.conversationMessages = []

    return endedSession
  }

  /**
   * Switch to different model within same session
   */
  async switchModel(newProvider: string, newModel: string): Promise<void> {
    if (!this.currentSession) {
      throw new Error('No active session to switch model')
    }

    const oldModel = `${this.currentSession.provider}:${this.currentSession.model}`

    this.currentSession.provider = newProvider
    this.currentSession.model = newModel
    this.currentSession.modelLimits = universalTokenizer.getModelLimits(newModel, newProvider)
    this.currentSession.lastActivity = new Date()

    logger.info('Switched model in active session', {
      sessionId: this.currentSession.sessionId,
      oldModel,
      newModel: `${newProvider}:${newModel}`
    })

    this.emit('model_switched', {
      session: this.currentSession,
      oldModel,
      newModel: `${newProvider}:${newModel}`
    })

    // Re-analyze optimization with new limits
    const optimization = this.analyzeContextOptimization()
    this.emit('context_reanalyzed', { session: this.currentSession, optimization })
  }

  /**
   * Get a formatted status string for display
   */
  getStatusString(): string {
    if (!this.currentSession) {
      return chalk.gray('No active session')
    }

    const totalTokens = this.currentSession.totalInputTokens + this.currentSession.totalOutputTokens
    const percentage = (totalTokens / this.currentSession.modelLimits.context) * 100
    const cost = this.currentSession.totalCost

    const tokenStr = totalTokens >= 1000 ? `${(totalTokens/1000).toFixed(1)}k` : totalTokens.toString()
    const limitStr = this.currentSession.modelLimits.context >= 1000
      ? `${(this.currentSession.modelLimits.context/1000).toFixed(0)}k`
      : this.currentSession.modelLimits.context.toString()

    const colorFn = percentage >= 90 ? chalk.red :
                   percentage >= 80 ? chalk.yellow :
                   chalk.green

    return colorFn(`${tokenStr}/${limitStr} (${percentage.toFixed(1)}%)`) +
           chalk.cyan(` | $${cost.toFixed(4)}`) +
           chalk.blue(` | ${this.currentSession.provider}:${this.currentSession.model}`)
  }

  // Private helper methods

  private generateSessionId(): string {
    return `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }

  private generateMessageId(): string {
    return `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }

  private trimMessageHistory(): void {
    if (this.messageHistory.size <= this.MAX_MESSAGES_HISTORY) return

    const entries = Array.from(this.messageHistory.entries())
      .sort((a, b) => a[1].timestamp.getTime() - b[1].timestamp.getTime())

    // Remove oldest entries
    const toRemove = entries.slice(0, entries.length - this.MAX_MESSAGES_HISTORY)
    for (const [id] of toRemove) {
      this.messageHistory.delete(id)
    }
  }
}

// Singleton instance
export const contextTokenManager = new ContextTokenManager()